{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k-tCpMTElmcb",
        "JVdnnCLUl3wg",
        "CQMfUBEQl-Vo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installing required packages"
      ],
      "metadata": {
        "id": "k-tCpMTElmcb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYTfE8xS-4x6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63ea1bb-ab8d-458a-9c8e-2fb1efcaaa82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain)\n",
            "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.128-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m697.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.128-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, python-dotenv, orjson, mypy-extensions, marshmallow, jsonpointer, h11, faiss-cpu, typing-inspect, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.8.0.post1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.1 langchain-community-0.3.1 langchain-core-0.3.6 langchain-text-splitters-0.3.0 langsmith-0.1.128 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 sentence-transformers-3.1.1 tenacity-8.5.0 typing-inspect-0.9.0\n",
            "Name: langchain-google-genai\n",
            "Version: 2.0.0\n",
            "Summary: An integration package connecting Google's genai package and LangChain\n",
            "Home-page: https://github.com/langchain-ai/langchain-google\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: google-generativeai, langchain-core, pydantic\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip install langchain faiss-cpu langchain-community sentence-transformers\n",
        "!pip install -q langchain-google-genai\n",
        "!pip install --upgrade -q langchain-google-genai\n",
        "!pip show langchain-google-genai\n",
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Gemini API key to evironment"
      ],
      "metadata": {
        "id": "zEgUFLOLltjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import getpass\n",
        "import os\n",
        "if 'GOOGLE_API_KEY' not in os.environ:\n",
        "    os.environ['GOOGLE_API_KEY'] = getpass.getpass('Provide your Google API Key: ')"
      ],
      "metadata": {
        "id": "tKLoj6hFggFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e477f5d2-6d15-4b33-e822-301b4a3bb6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Provide your Google API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load various models available by Google Gemini"
      ],
      "metadata": {
        "id": "JVdnnCLUl3wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
        "for model in genai.list_models():\n",
        "    print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfjcN3yIgUNM",
        "outputId": "baf62401-349f-4b23-a738-fb61ff3459cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/chat-bison-001\n",
            "models/text-bison-001\n",
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-pro-exp-0827\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-1.5-flash-002\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/aqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating some sample docuemnts"
      ],
      "metadata": {
        "id": "CQMfUBEQl-Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample documents\n",
        "import os\n",
        "\n",
        "folder_path = './docs'\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "documents_data = [\n",
        "    {\n",
        "        'source': 'quantum_computing.txt',\n",
        "        'content': '''Quantum computing is rapidly advancing, with significant breakthroughs in error correction, qubit coherence, and quantum algorithms. One of the key challenges facing quantum computing is maintaining qubit stability, as even slight environmental disturbances can cause qubits to lose coherence. However, recent advancements in error correction techniques, such as surface codes, are helping to mitigate this issue.\n",
        "\n",
        "In 2023, researchers achieved quantum supremacy for a specialized task, demonstrating that a quantum computer could perform a calculation faster than the most powerful classical computers. This breakthrough paves the way for practical quantum computing applications in areas such as cryptography, drug discovery, and materials science.\n",
        "\n",
        "Another promising development is the improvement in quantum hardware. New approaches to building qubits, including topological qubits and photonic qubits, are being explored to increase the scalability and reliability of quantum systems. As the field progresses, the race to build the first fully functional quantum computer continues, with tech giants and research institutions heavily investing in quantum technology.\n",
        "'''\n",
        "    },\n",
        "    {\n",
        "        'source': 'ai_impact_on_society.txt',\n",
        "        'content': '''Artificial intelligence (AI) is transforming various industries, from healthcare to finance, by automating tasks, optimizing processes, and providing deep insights from data. However, as AI becomes more prevalent, it raises significant ethical and societal concerns.\n",
        "\n",
        "One key issue is the potential loss of jobs due to automation. While AI can enhance productivity, many worry that automation will replace jobs, particularly in sectors like manufacturing and customer service. This has led to calls for retraining and reskilling programs to help workers adapt to the AI-driven economy.\n",
        "\n",
        "Another concern is bias in AI systems. Machine learning models are often trained on biased datasets, which can lead to discriminatory outcomes. For example, AI algorithms used in hiring or lending decisions might favor certain groups over others. Researchers are working on developing fair and transparent AI systems to mitigate these issues.\n",
        "\n",
        "Despite these challenges, AI has the potential to bring immense benefits. In healthcare, AI-powered tools can assist doctors in diagnosing diseases and personalizing treatments. In education, AI can provide tailored learning experiences for students. The key will be to harness AI's potential while addressing its risks through robust regulation and ethical frameworks.\n",
        "'''\n",
        "    },\n",
        "    {\n",
        "        'source': 'data_privacy.txt',\n",
        "        'content': '''As AI systems become more integrated into daily life, concerns over data privacy have become paramount. AI models require vast amounts of data to train, and much of this data is personal, ranging from browsing habits to medical records.\n",
        "\n",
        "One of the primary challenges in ensuring data privacy is that AI models can inadvertently reveal sensitive information. For instance, large language models trained on personal conversations or emails may unintentionally memorize and leak private details. To address this issue, researchers are developing techniques such as differential privacy, which allows AI models to learn from data while protecting individual privacy.\n",
        "\n",
        "Governments worldwide are enacting legislation to protect citizens' data. The General Data Protection Regulation (GDPR) in Europe is one of the most stringent data privacy laws, requiring companies to obtain explicit consent before collecting personal data. Similarly, the California Consumer Privacy Act (CCPA) gives consumers the right to know what data is being collected about them and to request its deletion.\n",
        "\n",
        "The future of AI will require a careful balance between innovation and privacy. Companies must prioritize transparency in their data practices and develop AI models that respect user privacy without compromising on performance.\n",
        "'''\n",
        "    },\n",
        "    {\n",
        "        'source': 'deploying_ai_models.txt',\n",
        "        'content': '''Deploying AI models in production environments comes with a unique set of challenges. One of the primary hurdles is the scalability of AI models. While many AI models perform well in controlled environments, scaling them to handle real-world data and workloads can be complex. Data pipelines need to be robust, and the infrastructure must be able to support the computational demands of large models.\n",
        "\n",
        "Another challenge is model explainability. Many AI models, particularly deep learning models, are considered \"black boxes,\" meaning it's difficult to understand how they arrive at their decisions. This lack of transparency is a problem in industries like healthcare and finance, where decisions need to be justified. Researchers are working on developing more interpretable AI models or providing post-hoc explanations for decisions made by complex models.\n",
        "\n",
        "Data privacy is another concern. AI models often require access to sensitive data, and ensuring that this data is handled securely is crucial. Techniques such as federated learning, where models are trained locally on devices without transferring data to central servers, are being explored to address this issue.\n",
        "\n",
        "Finally, AI models require constant monitoring and retraining. As new data becomes available, models may drift from their original performance, necessitating retraining to ensure they remain accurate and effective.\n",
        "'''\n",
        "    },\n",
        "    {\n",
        "        'source': 'ai_in_drug_discovery.txt',\n",
        "        'content': '''AI is playing a transformative role in drug discovery by accelerating the process of identifying potential drug candidates and optimizing clinical trials. Traditional drug discovery can take years, but AI models are helping to reduce this timeline by analyzing large datasets of chemical compounds, biological data, and patient information.\n",
        "\n",
        "One of the key applications of AI in drug discovery is virtual screening, where AI models predict the likelihood of certain molecules being effective against a disease target. These models can quickly sift through vast libraries of compounds to identify the most promising candidates for further testing.\n",
        "\n",
        "AI is also being used in precision medicine. By analyzing patient data, AI can help identify which treatments are most likely to be effective for individual patients, leading to more personalized and effective treatments. This approach has already shown promise in fields such as oncology, where AI models are helping to develop targeted therapies for cancer patients.\n",
        "\n",
        "The integration of AI into drug discovery is not without challenges. Data quality and availability are critical factors in training accurate AI models. Additionally, regulatory agencies are still adapting to AI-driven approaches, and ensuring that AI tools meet the necessary safety and efficacy standards will be essential.\n",
        "'''\n",
        "    }\n",
        "]\n",
        "\n",
        "for doc in documents_data:\n",
        "    with open(os.path.join(folder_path, doc[\"source\"]), 'w') as f:\n",
        "        f.write(doc['content'])"
      ],
      "metadata": {
        "id": "DwYMIFyLh1wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading documents, creating embeddings and storing in FAISS local store"
      ],
      "metadata": {
        "id": "k7IPZuF6mCjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize an empty list to store all document objects\n",
        "all_documents = []\n",
        "\n",
        "# Load each document and add to the list\n",
        "for file_path in [os.path.join(folder_path, document['source']) for document in documents_data]:\n",
        "    loader = TextLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split each document into chunks for efficient retrieval\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Add all the chunks to the list\n",
        "    all_documents.extend(docs)\n",
        "\n",
        "# Embedding using HuggingFace\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "\n",
        "# Create a FAISS vector store from the document chunks\n",
        "vector_store = FAISS.from_documents(all_documents, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "d2441ea9ca3245dd9dfc39fd447304fb",
            "d0cdcedc809f464abfbde8ba9e01438a",
            "523e3ad7e98e4994882c6e3d7edb5664",
            "fd39febfef2b423a85af318ecd3db834",
            "3668a6c6cff84a3bafd97f4c40d26901",
            "a52e1ca9d66e4aedae5a325ea44c88e9",
            "01379b9c61cc43289e665e9ace4887d4",
            "27a0a697f28d426b80bdb89b667b81a8",
            "635232c7dc1e41149a1b87db152ef126",
            "9b392da0dba64710bfbd27373e629561",
            "e5285e504f874705ba4105db27111edf",
            "fd398633c2d64dddb15c910777e34a46",
            "d94083d20747438c97e8467dd8040b58",
            "a4a92da5e78a4f068a88d3a6887f685a",
            "4c5fa0afe2554e2390796217e633c3f6",
            "194b3608412e46b6a22b69bdd9078401",
            "3d178317174b4846a42e2c9ddd19427c",
            "284d7fcf54904d84b9a6cbe704ea39cd",
            "abdcf970bba94bd0bafe2315d2638390",
            "d026c65015e4471992da950590b7373d",
            "0a0ea3bbddb74fa1acca5c8dfbc7203c",
            "8ff49bf96a584c1a80b3f2696a7bc7bf",
            "14abd9fa68ff46a0b2cf36c794f3d569",
            "f742079c396049bcbb53156c597d3f36",
            "6db140e1ba06484d88c5f059142bbe02",
            "42ce41a9373c493fa21c2a855f73be49",
            "66bcec9ccc7b4f9da3681168f9a43927",
            "8060fb0f99b842389f43e1a9216d4bed",
            "fd779b83cdbe42708c0695731a0aedbc",
            "cde02847df994196a671b2360851eaca",
            "bf0435b346c04d9999b8f85467f7b469",
            "ed6955f0505d4a0fb0576f5512bcd40d",
            "64d947b05e284a3dae3049fbf066719b",
            "8c0b531f0c7d4cc0bb985dba2587e4aa",
            "47dcd27678154816bad237d5b6ca3c04",
            "dd19c5bfcafd41d2bf87e01e9fc8e277",
            "8e106ccde7654e1d80c2cfda8aac33a9",
            "a0463f26fe46449383039be0530bb70a",
            "3f7e7ffbcc354b0e9bce3f45f965c504",
            "eaedd0cc30664ac98a81bcfcc5684418",
            "e65be2a296db4075bacb8bb9672888db",
            "42a66a22ddef465faec81388098faaa7",
            "621814b7a5b9470588f3399ecbc90f75",
            "44b5642186a9428c8a1ec8fb550b1dba",
            "b9ae12a9b1f84ef5890eb8c7ccbf52c7",
            "af7810f5c48143dfbe02f28d81cc32e4",
            "656c500e96d341778b85689b9781fc53",
            "7603cbb699414c12bf7b498e05fde5c5",
            "705d73dadebf48108b83b84270245ff1",
            "cbfdc8f3efbc4208b927237ec3e69c6d",
            "d9b7ddb511f84f69b0836401245a2417",
            "056336b2c1a04777852c656ab8338b13",
            "29589babd44343d2b1ae0444a47eb2ab",
            "713e89a1b5684249a5c45ecc160f0e84",
            "dd138198a2f8478a90b99d3078d940cb",
            "c6f0dfdd0a244dc18f104b13250e6866",
            "86a764bfff0c46e8bd8acd2493f82940",
            "4079805a49834a3cae81be3dc0c94b64",
            "ce5a6914acd742e8bd5b4c93e1dc819f",
            "cac2ef5df46a45fb9221e5c24ea01324",
            "f6024c34511f41ef80db7a705c792ab2",
            "86a380b4d20b466290352524dbd3702e",
            "7fe010c0457c4c059a3fc875bce765c9",
            "62d8685a76ea46e08dbdfd5bcbab40dc",
            "11d78941dafb443c9d0b19908e6e281c",
            "2121969e4f714282a96eab9a270b2683",
            "8a7f391d958f4f099df49bd8bb25dd5c",
            "75588b78977a4549b98ce637b4df7152",
            "37482b40a54544f98455f858a0639c93",
            "7c781af21b084b6782a2b1da5b23fc5e",
            "d8c1fffdee4b4431befc76c9bd80e2ef",
            "d445443a253f41f2a3e16051a48ebb12",
            "b8af9cc82ddf4c70924f6d9b468a9455",
            "1b41829133814b138d46871950b54dad",
            "7421a934edd34f1ba7d21deffdf9e6b3",
            "a88dbbd8d2564e51b52c59e9ae30c684",
            "f49f0d34df1d41df96db942958735560",
            "2aed4af091324d18b3e6e0230532e919",
            "b74ecfeed4f7414787d5e9c6e7c29780",
            "8e79141516124c1a971c310db91e22ca",
            "adffa60c2a0d45deab636408ba5d0950",
            "adaf8799411d40229ae34a3722249705",
            "58d862c844654f41b7b3c4309cc0a88f",
            "e0e46057e19c473f879db90061372281",
            "aeeb51d94f0d45478b5e135302aef029",
            "92bd492a858444b39455d5ad97c2e05e",
            "9c3954a4ccbb4775988dc5ea8abf5637",
            "5818fce55e1d4e97bf4944fe5932316f",
            "4d2f5ea7e9c34f9eacc637551ee944fe",
            "3386d3a01c45455cb2cfa27df9afa54c",
            "564f6653b456427db1c3260022b7198d",
            "44e0fa3920b64b48a82928314e9e5c88",
            "e2c34a811cac4e7f9dc157ea10e6feb9",
            "656fb5dfcafa4bf2974b992e2eb8ba8a",
            "8b9e6cfa95bb40d09e56dc433c001ce8",
            "f979ac8b32444d71ad82cb262ef3d984",
            "ca948a4493b849ef862cdb4f44601463",
            "6e7d01d020484893a2543d55a248e9b6",
            "e3965e83c4264d8a9096e1aa83741122",
            "5448ac370ec944a488c14c81a8195a25",
            "fbf6d0c5dcc147bc820e505cf23043b7",
            "b901eed9f01548b698631046065a3b74",
            "b5e429fdef6d4c1fbbe83b88de175b85",
            "aa4ef813c10c4ed7b6418fbc2ca033d6",
            "a17496e50daf4fb6b0d1a276d8e87a87",
            "4a309f52e68b401ebe2316fef93f4205",
            "2456288aa3cd44e59d910616f404787b",
            "b7b4eb821ff24778a408738746b87ecd",
            "962a576335584ce1bd28d9037a5f511f",
            "32798c876a5d4215a679f391366db740",
            "857b91e417a645e4a2404f401d11ce72",
            "10252f74288d4f7f855ed454f98b27a8",
            "4111f2317d774c25aed1b97f2a9ae225",
            "fb29e8de44cd4135b25b45023a948944",
            "d4103c8fba144421a6f577afb31f46e7",
            "6ec28ecc93fd49a0a680d30222ff3d8a",
            "b832a2fb41ee45f98d9e4c79489e1fd5",
            "86581717e6354601ba4620d875d57a41",
            "277ef923bdd64f83855fad65eb706a32",
            "a6da2ad2f95c4b09b501c103efbbbc62",
            "e34a0b3a17964a26b407ed29ae46e56d"
          ]
        },
        "id": "CVwiwtsmhUe7",
        "outputId": "48e787a3-d0a2-4f81-b216-7fc306abd18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-34818454cbb3>:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "<ipython-input-5-34818454cbb3>:22: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2441ea9ca3245dd9dfc39fd447304fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd398633c2d64dddb15c910777e34a46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14abd9fa68ff46a0b2cf36c794f3d569"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c0b531f0c7d4cc0bb985dba2587e4aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ae12a9b1f84ef5890eb8c7ccbf52c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f0dfdd0a244dc18f104b13250e6866"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a7f391d958f4f099df49bd8bb25dd5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2aed4af091324d18b3e6e0230532e919"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d2f5ea7e9c34f9eacc637551ee944fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5448ac370ec944a488c14c81a8195a25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "857b91e417a645e4a2404f401d11ce72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval-Augmented Generation (RAG) pipeline using LangChain's tools"
      ],
      "metadata": {
        "id": "7rnp1DsdmX1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an AI assistant capable of answering questions based on the following documents:\n",
        "\n",
        "Documents:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# Use FAISS to retrieve documents based on the query\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "\n",
        "# Initialize the Google Gemini language model\n",
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.9)\n",
        "\n",
        "# Define the RAG chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    chain_type=\"stuff\",\n",
        "    return_source_documents=True,\n",
        "    output_key=\"answer\"\n",
        ")"
      ],
      "metadata": {
        "id": "AcNakAG4hc6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing Input and Output, and answer generation"
      ],
      "metadata": {
        "id": "PdjMIbJtmua1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def query_rag_chain(query):\n",
        "    # Input parsing and query the RAG pipeline\n",
        "    result = rag_chain({\"query\": query})\n",
        "\n",
        "    # Output formatting: Display the answer and source documents\n",
        "    answer = result['answer']\n",
        "    sources = result['source_documents']\n",
        "\n",
        "    print(f\"Answer: {answer}\")\n",
        "    print(\"\\nSources:\")\n",
        "    for i, doc in enumerate(sources):\n",
        "        print(f\"{i+1}. {doc.metadata['source']}: {doc.page_content[:200]}...\")\n",
        "\n",
        "# Example input query\n",
        "# query = \"What are the latest advancements in quantum computing?\"\n",
        "# query = \"How does AI affect data privacy, and what are the main concerns? How do regulatory agencies adapt to AI-driven drug discovery approaches?\"\n",
        "query = \"How can federated learning address data privacy concerns in AI? How are quantum computers being used in drug discovery and materials science? How is it impacting job markets across different industries?\"\n",
        "query_rag_chain(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukxkP_9whqkC",
        "outputId": "9484d102-2161-4546-a7ba-696234be8ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e55e29cb7d12>:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = rag_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Here's what I can tell you based on the provided context:\n",
            "\n",
            "* **Federated learning and data privacy:**  The provided text explains that federated learning helps address data privacy concerns by training AI models locally on devices without transferring data to central servers. This means sensitive data remains on individual devices, reducing the risk of breaches or misuse.\n",
            "\n",
            "* **Quantum computers and drug discovery/materials science:** The provided context doesn't offer any information about quantum computers or their applications in drug discovery or materials science. \n",
            "\n",
            "* **Impact of AI on job markets:** The provided context doesn't offer information about the impact of AI on job markets across different industries. \n",
            "\n",
            "\n",
            "Sources:\n",
            "1. ./docs/deploying_ai_models.txt: Data privacy is another concern. AI models often require access to sensitive data, and ensuring that this data is handled securely is crucial. Techniques such as federated learning, where models are t...\n",
            "2. ./docs/data_privacy.txt: The future of AI will require a careful balance between innovation and privacy. Companies must prioritize transparency in their data practices and develop AI models that respect user privacy without c...\n",
            "3. ./docs/data_privacy.txt: As AI systems become more integrated into daily life, concerns over data privacy have become paramount. AI models require vast amounts of data to train, and much of this data is personal, ranging from...\n"
          ]
        }
      ]
    }
  ]
}